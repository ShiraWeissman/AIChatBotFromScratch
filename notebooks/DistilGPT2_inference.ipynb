{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c91ec8e-9127-493b-9683-dc5277963e54",
   "metadata": {},
   "source": [
    "##This notebook loads the trained DistilGPT2 question-answering model, accept new question and reply answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3e8ca9-11b7-49b8-889c-bd1c34f7b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://ShiraWeissman:<token>@github.com/ShiraWeissman/AIChatBotFromScratch.git\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "# !pip3 install pyyaml\n",
    "# !pip3 install evaluate\n",
    "# !pip3 install transformers[torch]\n",
    "# !pip3 install numpy\n",
    "# !pip3 install datasets\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.pardir))\n",
    "# sys.path.append('AIChatBotFromScratch')\n",
    "from src.inference.distilgpt2_inference import load_tokenizer, generate_response\n",
    "from models.distilgpt2_model.model import load_model\n",
    "from src.utils import root_path, load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ed372-65e7-4155-bc57-eccc28cc1c98",
   "metadata": {},
   "source": [
    "Loading configuration, model and tokenizer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597cf67e-24cd-4fb2-98d1-c3343a9abcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tinystories dataset from Hugging Face...\n",
      "100\n",
      "Preprocessing tinystories for distilpt2 model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814a338a6ea04b16a4e39b89798e79af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418a7beaff224174962daa1bf814155a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved at C:\\Users\\Shira\\Desktop\\DSProjects\\AIChatBotFromScratch\\data/processed/tinystories_distilpt2_preprocessed.pkl\n"
     ]
    }
   ],
   "source": [
    "config = load_config(\"distilgpt2_inference_config\")\n",
    "model = load_model(task_type=\"question_answering\",\n",
    "                   pretrained_model_name=os.path.join(root_path, config[\"model\"][\"path\"]))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "tokenizer = load_tokenizer(model_type=\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b26be-bbad-4b61-9313-50be2983abde",
   "metadata": {},
   "source": [
    "## Please write a question in the Fairytale domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95cf693-52ab-4d7a-b072-0e355e79cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training configuration..\n",
      "Loading dataset..\n",
      "Loading model..\n",
      "Loading DistilGPT2ForLanguageModeling..\n",
      "Loading configuration...\n",
      "Loading model...\n",
      "Loading tokenizer...\n",
      "Setting padding token...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the most common hero name?\"\n",
    "response = generate_response(question, model, tokenizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909ab8b6-e5de-4380-9f01-657f523f528b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuestion:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mquestion\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerated Text:\u001b[39m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[31mNameError\u001b[39m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Question:\", question)\n",
    "print(\"Generated Text:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab87d97-c75c-46f4-8d20-6475bb83fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_dataset, valid_dataset, config = prepare_for_training(task_type=\"question_answering\")\n",
    "train_model(model, train_dataset, valid_dataset, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
