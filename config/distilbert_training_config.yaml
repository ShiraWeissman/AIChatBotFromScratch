language_modeling:
  dataset_type: "language_modeling"  # "language_modeling" for TinyStories, "question_answering" for FairytaleQA
  dataset_name: "tinystories"
  data_path: "data/processed"
  checkpoint_dir: "models/distilbert_LM_model/checkpoints"
  pretrained_model_name: "distilbert-base-uncased"
  model_type: "distilbert"

  training:
    batch_size: 16
    epochs: 3
    learning_rate: 5e-5
  device: "cuda"  # "cuda" for GPU, "cpu" for CPU
question_answering:
  dataset_type: "question_answering"  # "language_modeling" for TinyStories, "question_answering" for FairytaleQA
  dataset_name: "fairytaleQA"
  data_path: "data/processed"
  checkpoint_dir: "models/distilbert_QA_model/checkpoints"
  pretrained_model_name: "train/models/distilbert_lm"
  model_type: "distilbert"

  training:
    batch_size: 16
    epochs: 3
    learning_rate: 5e-5
  device: "cuda"  # "cuda" for GPU, "cpu" for CPU
